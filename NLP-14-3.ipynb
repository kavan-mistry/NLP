{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8313ecf-c497-4d2f-8e45-af4378831adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kavan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a260e3-2e69-4e2a-9a08-454b220bab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2516de3f-4db0-46b8-8ac9-3ad60c580a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_document(document):\n",
    "    tokens = word_tokenize(document)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b6c0a8-d14a-4bea-864c-0f429fe63a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document('doc1.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6028c1-59a9-4a06-bbab-4c4ac1d2a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1d4b24-55b7-43e8-848e-0e8eb8f8242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for paragraph in doc.paragraphs:\n",
    "    document_text += paragraph.text + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9210f6be-0aed-48c1-ac6e-db64f60d19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_document = tokenize_document(document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd24adf3-b5f6-43ac-bb67-f9fa625ce93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized document:\n",
      "['Rabindranath', 'Tagore', 'was', 'the', 'first', 'to', 'call', 'Gandhiji', \"'Mahatma\", ',', \"'\", 'which', 'means', \"'Great\", 'Soul', \"'\", 'in', 'Sanskrit', '.', 'His', 'wise', 'ideas', 'and', 'beliefs', 'led', 'people', 'to', 'respect', 'and', 'call', 'him', \"'Mahatma\", 'Gandhi', '.', \"'\", 'His', 'dedication', 'to', 'the', 'country', 'and', 'efforts', 'to', 'turn', 'his', 'ideas', 'into', 'reality', 'make', 'Indians', 'around', 'the', 'world', 'very', 'proud', 'of', 'him', '.', 'According', 'to', 'Mahatma', 'Gandhi', '’', 's', 'biography', ',', 'he', 'was', 'born', 'on', 'October', '2', ',', '1869', ',', 'in', 'Porbandar', ',', 'a', 'coastal', 'town', 'in', 'the', 'present-day', 'Indian', 'state', 'of', 'Gujarat', '.', 'He', 'grew', 'up', 'in', 'a', 'Hindu', 'family', 'and', 'ate', 'basic', 'vegetarian', 'meals', '.', 'His', 'dad', ',', 'Karamchand', 'Uttamchand', 'Gandhi', ',', 'was', 'an', 'important', 'leader', 'in', 'Porbandar', 'State', '.', 'In', 'South', 'Africa', ',', 'he', 'was', 'the', 'first', 'to', 'lead', 'a', 'peaceful', 'protest', 'movement', ',', 'setting', 'him', 'apart', 'from', 'other', 'demonstrators', '.', 'Mahatma', 'Gandhi', 'also', 'introduced', 'the', 'idea', 'of', 'Satyagraha', ',', 'a', 'nonviolent', 'approach', 'to', 'opposing', 'unfairness', '.', 'He', 'devoted', '20', 'years', 'of', 'his', 'life', 'to', 'battling', 'discrimination', 'in', 'South', 'Africa', '.', 'His', 'idea', 'of', \"'Ahimsa\", ',', \"'\", 'which', 'means', 'not', 'hurting', 'anyone', ',', 'was', 'widely', 'admired', 'and', 'followed', 'by', 'many', 'influential', 'people', 'worldwide', '.', 'He', 'became', 'an', 'indomitable', 'figure', 'who', 'could', \"n't\", 'be', 'defeated', 'in', 'any', 'situation', '.', 'Mahatma', 'Gandhi', 'initiated', 'the', \"'Khadi\", 'Movement', \"'\", 'to', 'encourage', 'the', 'use', 'of', 'fabrics', 'like', 'khadi', 'or', 'jute', '.', 'This', 'movement', 'was', 'a', 'crucial', 'part', 'of', 'the', 'larger', \"'Non-co-operation\", 'Movement', ',', \"'\", 'which', 'advocated', 'for', 'Indian', 'goods', 'and', 'discouraged', 'foreign', 'ones', '.', 'Gandhi', 'strongly', 'supported', 'agriculture', 'and', 'encouraged', 'people', 'to', 'engage', 'in', 'farming', '.', 'He', 'inspired', 'Indians', 'to', 'embrace', 'manual', 'labor', 'and', 'emphasized', 'self-reliance', ',', 'urging', 'them', 'to', 'provide', 'for', 'their', 'needs', 'and', 'lead', 'simple', 'lives', '.', 'He', 'began', 'weaving', 'cotton', 'clothes', 'using', 'the', 'Charkha', 'to', 'reduce', 'dependence', 'on', 'foreign', 'goods', 'and', 'promote', 'Swadeshi', 'products', 'among', 'Indians', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized document:\")\n",
    "print(tokenized_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d508f26a-b952-4fff-9665-dcfa8611efee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized document:\n",
      "['During', 'the', 'fight', 'for', 'India', \"'s\", 'freedom', ',', 'Gandhiji', 'faced', 'imprisonment', 'several', 'times', 'along', 'with', 'his', 'followers', ',', 'but', 'his', 'main', 'goal', 'was', 'always', 'the', 'freedom', 'of', 'his', 'motherland', '.', 'Even', 'when', 'he', 'was', 'in', 'prison', ',', 'he', 'never', 'chose', 'the', 'path', 'of', 'violence', '.', 'Mahatma', 'Gandhi', 'made', 'significant', 'contributions', 'to', 'various', 'social', 'issues', '.', 'His', 'efforts', 'against', \"'untouchability\", \"'\", 'while', 'he', 'was', 'in', 'Yerwada', 'Jail', ',', 'where', 'he', 'went', 'on', 'a', 'hunger', 'strike', 'against', 'this', 'ancient', 'social', 'evil', ',', 'greatly', 'helped', 'uplift', 'the', 'oppressed', 'community', 'in', 'modern', 'times', '.', 'He', 'also', 'emphasized', 'the', 'importance', 'of', 'education', ',', 'cleanliness', ',', 'health', ',', 'and', 'equality', 'in', 'society', '.', 'These', 'qualities', 'defined', 'him', 'as', 'a', 'person', 'with', 'a', 'great', 'soul', 'and', 'justified', 'his', 'transformation', 'from', 'Gandhi', 'to', 'Mahatma', '.', 'He', 'led', 'many', 'freedom', 'movements', ',', 'including', 'the', '``', 'Quit', 'India', 'Movement', ',', \"''\", 'which', 'was', 'highly', 'successful', '.', 'His', 'death', 'was', 'a', 'huge', 'loss', 'to', 'the', 'forces', 'of', 'peace', 'and', 'democracy', ',', 'leaving', 'a', 'significant', 'void', 'in', 'the', 'nation', \"'s\", 'life', '.', 'Gopal', 'Krishna', 'Gokhale', ',', 'a', 'prominent', 'Indian', 'nationalist', 'leader', ',', 'significantly', 'influenced', 'Mahatma', 'Gandhi', \"'s\", 'political', 'ideology', 'and', 'leadership', 'approach', '.', 'Gandhi', 'considered', 'him', 'his', 'political', 'teacher', '.']\n"
     ]
    }
   ],
   "source": [
    "doc2 = Document('doc2.docx')\n",
    "document_text2 = \"\"\n",
    "\n",
    "for paragraph in doc2.paragraphs:\n",
    "    document_text2 += paragraph.text + \"\\n\"\n",
    "\n",
    "tokenized_document2 = tokenize_document(document_text2)\n",
    "\n",
    "print(\"Tokenized document:\")\n",
    "print(tokenized_document2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3603cc14-9443-4ee0-893e-f59279f6b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized document:\n",
      "['Mahatma', 'Gandhi', 'played', 'a', 'crucial', 'role', 'in', 'India', \"'s\", 'fight', 'for', 'freedom', 'from', 'British', 'rule', '.', 'His', 'life', 'was', 'dedicated', 'to', 'serving', 'his', 'country', 'and', 'its', 'people', ',', 'and', 'he', 'became', 'an', 'international', 'symbol', 'of', 'Indian', 'leadership', '.', 'Even', 'today', ',', 'he', 'continues', 'to', 'inspire', 'and', 'motivate', 'young', 'people', 'worldwide', 'with', 'his', 'values', 'and', 'principles', '.']\n"
     ]
    }
   ],
   "source": [
    "doc3 = Document('doc3.docx')\n",
    "document_text3 = \"\"\n",
    "\n",
    "for paragraph in doc3.paragraphs:\n",
    "    document_text3 += paragraph.text + \"\\n\"\n",
    "\n",
    "tokenized_document3 = tokenize_document(document_text3)\n",
    "\n",
    "print(\"Tokenized document:\")\n",
    "print(tokenized_document3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4a15910-0832-401e-887d-220f99320a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized document:\n",
      "['Gandhi', 'Ji', 'was', 'known', 'for', 'his', 'strong', 'sense', 'of', 'discipline', '.', 'He', 'emphasized', 'the', 'importance', 'of', 'self-discipline', 'in', 'achieving', 'significant', 'goals', ',', 'a', 'principle', 'he', 'applied', 'in', 'promoting', 'his', 'philosophy', 'of', 'Ahimsa', '(', 'non-violence', ')', '.', 'Through', 'his', 'own', 'life', ',', 'he', 'demonstrated', 'that', 'rigorous', 'discipline', 'can', 'lead', 'to', 'the', 'realization', 'of', 'any', 'objective', ',', 'provided', 'we', 'remain', 'committed', 'and', 'dedicated', '.', 'These', 'qualities', 'established', 'him', 'as', 'a', 'revered', 'and', 'respected', 'leader', 'whose', 'influence', 'extends', 'far', 'beyond', 'his', 'lifetime', '.', 'His', 'ideals', 'continue', 'to', 'resonate', 'not', 'only', 'in', 'India', 'but', 'also', 'around', 'the', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "doc4 = Document('doc4.docx')\n",
    "document_text4 = \"\"\n",
    "\n",
    "for paragraph in doc4.paragraphs:\n",
    "    document_text4 += paragraph.text + \"\\n\"\n",
    "\n",
    "tokenized_document4 = tokenize_document(document_text4)\n",
    "\n",
    "print(\"Tokenized document:\")\n",
    "print(tokenized_document4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca20b67d-285f-467f-b95c-540a1531b6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized document:\n",
      "['Everyone', 'has', 'dreams', 'and', 'plans', 'for', 'the', 'future', '.', 'In', 'our', 'childhood', ',', 'we', 'dream', 'of', 'becoming', 'a', 'doctor', ',', 'an', 'engineer', ',', 'an', 'astronaut', ',', 'etc', '.', 'It', '’', 's', 'we', 'who', 'really', 'know', 'best', 'what', 'we', 'like', '.', 'We', 'know', 'what', 'we', 'want', 'in', 'our', 'life', '.', 'Future', 'plans', 'can', 'be', 'different', 'for', 'different', 'students', '.', 'Below', 'is', 'just', 'a', 'sample', 'essay', 'that', 'students', 'can', 'use', 'for', 'reference', '.', 'This', 'future', 'plan', 'essay', 'will', 'help', 'students', 'to', 'write', 'an', 'effective', 'essay', 'on', 'their', 'future', 'plans', '.', 'They', 'can', 'also', 'get', 'the', 'list', 'of', 'CBSE', 'Essays', 'on', 'different', 'topics', 'for', 'their', 'practice', '.', 'It', 'will', 'boost', 'their', 'score', 'in', 'English', 'exams', 'and', 'also', 'help', 'them', 'to', 'participate', 'in', 'various', 'essay', 'writing', 'competitions', '.']\n"
     ]
    }
   ],
   "source": [
    "doc5 = Document('doc5.docx')\n",
    "document_text5 = \"\"\n",
    "\n",
    "for paragraph in doc5.paragraphs:\n",
    "    document_text5 += paragraph.text + \"\\n\"\n",
    "\n",
    "tokenized_document5 = tokenize_document(document_text5)\n",
    "\n",
    "print(\"Tokenized document:\")\n",
    "print(tokenized_document5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df260739-b7c2-449d-88d5-4cc576ac3014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized document:\n",
      "['Similarly', ',', 'rushing', 'to', 'the', 'bus', 'stop', 'is', 'very', 'exciting', 'during', 'student', 'life', '.', 'The', 'mothers', 'constantly', 'remind', 'us', 'to', 'hurry', 'up', 'and', 'not', 'be', 'late', '.', 'It', 'is', 'no', 'less', 'than', 'a', 'mantra', 'for', 'all', 'mothers', '.', 'In', 'addition', ',', 'there', 'are', 'other', 'exciting', 'moments', 'in', 'student', 'life', '.', 'We', 'sometimes', 'forget', 'to', 'complete', 'our', 'homework', 'and', 'then', 'pretend', 'to', 'find', 'the', 'notebook', 'when', 'the', 'teacher', 'asks', 'for', 'it', '.']\n"
     ]
    }
   ],
   "source": [
    "doc6 = Document('doc6.docx')\n",
    "document_text6 = \"\"\n",
    "\n",
    "for paragraph in doc6.paragraphs:\n",
    "    document_text6 += paragraph.text + \"\\n\"\n",
    "\n",
    "tokenized_document6 = tokenize_document(document_text6)\n",
    "\n",
    "print(\"Tokenized document:\")\n",
    "print(tokenized_document6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d3c4043-2eee-47b5-9039-bd6363b10c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique words:\n",
      "{'.', 'life', 'Rabindranath', 'anyone', 'discouraged', 'goods', \"'Mahatma\", 'cotton', 'people', 'present-day', 'of', 'Mahatma', \"n't\", 'up', 'basic', 'embrace', 'and', 'Sanskrit', 'promote', 'first', 'khadi', 'leader', 'foreign', 'Charkha', 'was', 'opposing', 'demonstrators', '20', 'movement', 'engage', 'situation', 'ideas', 'introduced', 'Satyagraha', 'encouraged', 'crucial', 'According', 'Indian', 'apart', \"'Ahimsa\", 'admired', 'from', 'larger', 'South', '’', 'indomitable', 'inspired', 'around', 'beliefs', 'Indians', 'grew', 'fabrics', 'supported', ',', 'needs', 'setting', 'Porbandar', 'a', 'who', 'coastal', 'for', 'October', 'him', 'Gujarat', 'in', 'clothes', 'dedication', 'jute', 'by', 'could', 'led', 'part', 'them', 'advocated', 'Tagore', '1869', 'family', 'Uttamchand', 'initiated', 'began', 'state', 'Karamchand', 'This', 'simple', 'call', 'Africa', 'followed', 'became', 'an', 'proud', 'defeated', 'very', 'he', 'agriculture', 'idea', 'Gandhi', 'self-reliance', 'to', 'widely', 'Soul', 'make', 'world', 's', 'their', 'not', 'country', 'lead', 'His', 'among', 'labor', 'strongly', 'dependence', 'Swadeshi', 'Gandhiji', 'influential', 'emphasized', 'Movement', 'ones', 'provide', \"'Khadi\", 'the', 'years', 'or', 'worldwide', 'In', 'like', 'State', 'efforts', 'battling', 'approach', 'using', \"'Non-co-operation\", 'also', 'vegetarian', 'He', '2', 'manual', 'reality', 'products', 'born', 'turn', 'on', \"'\", 'discrimination', 'peaceful', 'protest', 'devoted', 'which', 'into', 'town', 'other', 'weaving', 'lives', 'respect', 'nonviolent', 'meals', 'figure', 'important', 'unfairness', 'hurting', 'many', 'means', 'encourage', 'any', 'urging', 'biography', 'be', 'use', 'farming', 'ate', 'reduce', 'Hindu', 'his', 'wise', \"'Great\", 'dad'}\n"
     ]
    }
   ],
   "source": [
    "unique_words = set(tokenized_document)\n",
    "\n",
    "# Print unique words\n",
    "print(\"Unique words:\")\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09ca756a-a48c-4dbd-84b9-a38b63ce5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d954a527-d2b8-4e02-b88a-2f8b13abde27",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = string.punctuation\n",
    "\n",
    "combined_unique_words = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0ee53b0-da28-4e95-9f04-ee1e65504f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    variable_name = f\"tokenized_document{i}\"\n",
    "    if variable_name in globals() and isinstance(globals()[variable_name], list):\n",
    "        unique_words = set(globals()[variable_name])\n",
    "        # Remove punctuation from unique words\n",
    "        unique_words = {word for word in unique_words if word not in punctuation}\n",
    "        # Combine unique words with the existing set\n",
    "        combined_unique_words = combined_unique_words.union(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa1c6801-1439-4cb3-87ca-fbd5569d21a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined unique words:\n",
      "{'competitions', 'life', 'goal', 'modern', 'forces', 'void', 'resonate', 'becoming', 'only', 'homework', 'people', 'practice', 'participate', 'of', 'Mahatma', 'never', 'up', 'today', 'we', 'ideals', 'and', 'highly', 'leader', 'where', 'During', 'addition', 'significant', 'was', 'values', 'principles', 'strong', 'dream', 'Gokhale', 'helped', 'want', 'greatly', 'international', 'The', 'peace', 'fight', 'engineer', \"'untouchability\", 'equality', 'society', 'imprisonment', 'teacher', 'bus', 'loss', 'is', 'while', 'These', 'crucial', 'Indian', 'reference', 'no', \"''\", 'strike', 'non-violence', 'during', 'boost', 'as', 'from', 'inspire', 'Ji', 'remain', 'sense', 'influence', 'Future', 'issues', 'importance', 'dedicated', 'this', 'It', 'hunger', '’', 'motivate', 'around', 'uplift', 'goals', 'topics', 'complete', 'chose', 'constantly', 'Gopal', 'score', 'leadership', 'effective', 'considered', 'a', 'Krishna', 'who', 'for', 'him', 'student', 'in', 'against', 'main', 'led', 'person', 'them', '``', 'great', 'best', 'beyond', 'different', 'moments', 'along', 'all', 'astronaut', 'huge', 'find', 'always', 'write', 'democracy', 'etc', 'nation', 'This', 'defined', 'became', 'achieving', 'are', 'an', 'Similarly', 'soul', 'social', 'motherland', 'us', 'influenced', 'he', 'get', 'We', 'very', 'cleanliness', 'Gandhi', 'sample', 'to', 'evil', \"'s\", 'late', 'Even', 'world', 'our', 'realization', 'established', 'including', 'notebook', 'Quit', 'successful', 's', 'will', 'their', 'not', 'know', 'several', 'country', 'made', 'oppressed', 'serving', 'lead', 'community', 'His', 'ancient', 'really', 'plans', 'self-discipline', 'revered', 'extends', 'list', 'significantly', 'far', 'rigorous', 'its', 'English', 'mothers', 'qualities', 'respected', 'Gandhiji', 'went', 'there', 'ideology', 'followers', 'emphasized', 'Movement', 'demonstrated', 'the', 'continue', 'worldwide', 'CBSE', 'role', 'Everyone', 'pretend', 'In', 'like', 'They', 'efforts', 'that', 'prison', 'approach', 'young', 'childhood', 'leaving', 'dreams', 'future', 'times', 'what', 'movements', 'also', 'prominent', 'He', 'with', 'mantra', 'exciting', 'then', 'but', 'lifetime', 'just', 'sometimes', 'education', 'nationalist', 'discipline', 'played', 'contributions', 'on', 'exams', 'known', 'remind', 'when', 'has', 'promoting', 'rushing', 'help', 'violence', 'which', 'Essays', 'stop', 'health', 'principle', 'transformation', 'rule', 'other', 'essay', 'Jail', 'own', 'Through', 'death', 'political', 'various', 'whose', 'British', 'plan', 'less', 'India', 'many', 'writing', 'path', 'Below', 'justified', 'any', 'freedom', 'continues', 'applied', 'be', 'doctor', 'use', 'can', 'Ahimsa', 'philosophy', 'symbol', 'faced', 'provided', 'students', 'Yerwada', 'forget', 'it', 'committed', 'than', 'hurry', 'asks', 'his', 'objective'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Combined unique words:\")\n",
    "print(combined_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfee4b46-7ce9-4155-ac79-293798cb7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2b15297-bd2e-4736-84a0-fb9a9ab7c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_unique_words = list(combined_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd121706-8d74-43e2-9c47-822dc861ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(0, index=combined_unique_words, columns=[f\"tokenized_document{i}\" for i in range(1, 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "669bb1a8-9fe4-4e7a-9b4b-522a73bc314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    variable_name = f\"tokenized_document{i}\"\n",
    "    if variable_name in globals() and isinstance(globals()[variable_name], list):\n",
    "        for word in globals()[variable_name]:\n",
    "            if word in df.index:\n",
    "                df.at[word, variable_name] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00639b94-3f8a-4722-a752-ffd263628a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_document1</th>\n",
       "      <th>tokenized_document2</th>\n",
       "      <th>tokenized_document3</th>\n",
       "      <th>tokenized_document4</th>\n",
       "      <th>tokenized_document5</th>\n",
       "      <th>tokenized_document6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>competitions</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modern</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forces</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>than</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurry</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asks</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              tokenized_document1  tokenized_document2  tokenized_document3  \\\n",
       "competitions                    0                    0                    0   \n",
       "life                            0                    1                    1   \n",
       "goal                            0                    1                    0   \n",
       "modern                          0                    1                    0   \n",
       "forces                          0                    1                    0   \n",
       "...                           ...                  ...                  ...   \n",
       "than                            0                    0                    0   \n",
       "hurry                           0                    0                    0   \n",
       "asks                            0                    0                    0   \n",
       "his                             0                    1                    1   \n",
       "objective                       0                    0                    0   \n",
       "\n",
       "              tokenized_document4  tokenized_document5  tokenized_document6  \n",
       "competitions                    0                    1                    0  \n",
       "life                            1                    1                    1  \n",
       "goal                            0                    0                    0  \n",
       "modern                          0                    0                    0  \n",
       "forces                          0                    0                    0  \n",
       "...                           ...                  ...                  ...  \n",
       "than                            0                    0                    1  \n",
       "hurry                           0                    0                    1  \n",
       "asks                            0                    0                    1  \n",
       "his                             1                    0                    0  \n",
       "objective                       1                    0                    0  \n",
       "\n",
       "[280 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee9ea678-8c4c-4668-8b76-f6d823cd72ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to document_word_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('document_word_matrix.csv')\n",
    "print(\"DataFrame saved to document_word_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39f43702-c189-4865-b5d4-a3ead462e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_search = ['hunger', 'dedicated', 'health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71d845d4-4ec7-434e-be14-506ca73577f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: hunger\n",
      "In tokenized_document2\n",
      "Word: dedicated\n",
      "In tokenized_document3\n",
      "In tokenized_document4\n",
      "Word: health\n",
      "In tokenized_document2\n"
     ]
    }
   ],
   "source": [
    "word_presence = {}\n",
    "\n",
    "for word in words_search:\n",
    "    word_presence[word] = {}\n",
    "    for i in range(0, 7):\n",
    "        variable_name = f\"tokenized_document{i}\"\n",
    "        if variable_name in globals() and isinstance(globals()[variable_name], list):\n",
    "            word_presence[word][variable_name] = word in globals()[variable_name]\n",
    "\n",
    "for word, presence_dict in word_presence.items():\n",
    "    print(f\"Word: {word}\")\n",
    "    for doc, presence in presence_dict.items():\n",
    "        if presence == True:\n",
    "            print(f\"In {doc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d381145-f0f1-4600-886d-83637e500050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both 'life' and 'Mahatma' are present in the same document(s):\n",
      "- Document tokenized_document2\n",
      "- Document tokenized_document3\n"
     ]
    }
   ],
   "source": [
    "# Check if 'hunger' and 'dedicated' are present in the index\n",
    "if 'life' in df.index and 'Mahatma' in df.index:\n",
    "    # Get the document numbers where 'hunger' and 'dedicated' are present\n",
    "    documents_with_1 = df.columns[df.loc['life'] > 0].tolist()\n",
    "    documents_with_2 = df.columns[df.loc['Mahatma'] > 0].tolist()\n",
    "\n",
    "    # Check if both words are present in the same document\n",
    "    common_documents = set(documents_with_1).intersection(documents_with_2)\n",
    "    if len(common_documents) > 0:\n",
    "        print(\"Both 'life' and 'Mahatma' are present in the same document(s):\")\n",
    "        for doc in common_documents:\n",
    "            print(f\"- Document {doc}\")\n",
    "    else:\n",
    "        print(\"Either 'life' or 'Mahatma' is not present in any document.\")\n",
    "else:\n",
    "    print(\"One or both of the words are not present in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b34720fc-3bbe-43bf-8c00-18ec4065e6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both 'life' and 'Mahatma' are present in the same document(s) where 'never' is not present:\n",
      "- Document tokenized_document3\n"
     ]
    }
   ],
   "source": [
    "# Check if 'hunger', 'dedicated', and 'never' are present in the index\n",
    "if 'life' in df.index and 'Mahatma' in df.index and 'never' in df.index:\n",
    "    # Get the document numbers where 'never' is not present\n",
    "    documents_without_never = df.columns[df.loc['never'] == 0].tolist()\n",
    "    \n",
    "    # Get the document numbers where 'hunger' and 'dedicated' are present\n",
    "    documents_with_hunger = df.columns[df.loc['life'] > 0].tolist()\n",
    "    documents_with_dedicated = df.columns[df.loc['Mahatma'] > 0].tolist()\n",
    "\n",
    "    # Get the common documents where 'hunger' and 'dedicated' are present and 'never' is not present\n",
    "    common_documents = set(documents_with_hunger).intersection(documents_with_dedicated, documents_without_never)\n",
    "    \n",
    "    if len(common_documents) > 0:\n",
    "        print(\"Both 'life' and 'Mahatma' are present in the same document(s) where 'never' is not present:\")\n",
    "        for doc in common_documents:\n",
    "            print(f\"- Document {doc}\")\n",
    "    else:\n",
    "        print(\"Either 'life' or 'Mahatma' is not present in any document, or 'never' is present in all common documents.\")\n",
    "else:\n",
    "    print(\"One or more of the words are not present in the vocabulary.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
